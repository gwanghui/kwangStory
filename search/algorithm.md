# Algorithm

* Google

1. **판다\(Google Panda, 2011년\)**: 광고 또는 제휴사 링크가 과하게 올려져 있는 낮은 수준의 콘텐츠 품질, 키워드 스터핑, 저조한 UX와 표절과 같은 블랙햇 전략을 실행한 웹사이트들에게 페널티를 주고 뉴스 사이트에는 순위 상승을 줌
2. **펭귄\(Penguin, 2012년\)**: 링크의 품질 기준을 강화하여 제3자 사이트들로부터 백링크를 구매한 웹사이트에게 페널티를 줌
3. **허밍버드\(Hummingbird, 2013년\)**: 구글이 검색 문의를 잘 파악한 후 검색 의도에 적합한 결과를 제공할 수 있도록 도움을 주기 위해 업데이트 된 알고리즘으로서, 검색자의 의도를 파악하기 때문에 사이트가 정확히 검색 단어를 갖고 있지 않아도 페이지가 검색엔진 결과 페이지\(SERP\)에서 랭킹에 들 수 있게끔 함. 아울러 키워드 스터핑과 저질 콘텐츠를 사용한 사이트에게 페널티를 줌
4. **피죤\(Pigeon, 2014년\)**: 적절하지 않은 온페이지 및 오프페이지 SEO에 페널티를 줌. 피죤 업데이트를 함으로써 검색자의 위치와 다른 지리적인 요인을 고려하여 더 적절하고 정확한 결과를 제공함.
5. **랭크-브레인\(Rank-Brain, 2015년\)**: 머신 러닝 AI\(Artificial Intelligence\) 알고리즘이라고도 알려진 랭크-브레인 알고리즘은 키워드 검색 결과를 제공할 때 검색자의 의도를 파악하는 과정을 개선시켰음. 인공지능의 한 분야인 머신 러닝 기법을 이용하여 컴퓨터가 사람한테 배우지 않고 혼자서 특정 업무를 배워서 익힌 후 실행할 수 있도록 함으로써, 얕은 지식으로 만들어진 콘텐츠, 표절했거나 관련된 검색 쿼리에 거의 가치를 더하지 않은 콘텐츠, 스팸, 키워드 스터핑을 사용한 웹사이트를 더욱 잘 식별하게 됨
6. **포썸\(Possum, 2016년\)**: 로컬\(Local\) SEO에 대해 다양한 변화를 줌. 검색자의 실제 위치에 따라 그 주변에 있는 회사에게는 검색엔진결과페이지에 노출 될 확률이 더 높아짐. 단 많은 지역에 여러 개의 사무실을 갖고 있으나 NAP\(Name, Address, Phone number\)이 같은 정보만 등록되어 있는 회사는 랭킹이 하락함
7. **프레드\(Fred, 2017년\)**: 전문성, 권위성, 신뢰성을 바탕으로 웹페이지 랭킹 점수를 조정함

* Elastic Search

1. **TF-IDF\(Term Frequency - Inverse Document Frequency,  단어 빈도- 역 문서 빈도\)**: TF-IDF는 Term Frequency-Inverse Document Frequency의 줄임말로, 단어의 빈도와 역 문서 빈도\(문서의 빈도에 특정 식을 취함\)를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법입니다. 사용 방법은 우선 DTM을 만든 후에, 거기에 TF-IDF 가중치를 주면됩니다.

   TF-IDF는 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰일 수 있습니다.

   TF-IDF는 TF와 IDF를 곱한 값을 의미하는데 이를 식으로 표현해보겠습니다. 문서를 d, 단어를 t, 문서의 총 개수를 n이라고 표현할 때 TF, DF, IDF는 각각 다음과 같이 정의할 수 있습니다.

   **\(1\) tf\(d,t\) : 특정 문서 d에서의 특정 단어 t의 등장 횟수.**

   생소한 글자때문에 어려워보일 수 있지만, 잘 생각해보면 TF는 이미 앞에서 구한 적이 있습니다. TF는 앞에서 배운 DTM의 예제에서 각 단어들이 가진 값들입니다. DTM이 각 문서에서의 각 단어의 등장 빈도를 나타내는 값이었기 때문입니다.

   **\(2\) df\(t\) : 특정 단어 t가 등장한 문서의 수.**

   여기서 특정 단어가 각 문서, 또는 문서들에서 몇 번 등장했는지는 관심가지지 않으며 오직 특정 단어 t가 등장한 문서의 수에만 관심을 가집니다. 앞서 배운 DTM에서 바나나는 문서2와 문서3에서 등장했습니다. 이 경우, 바나나의 df는 2입니다. 문서3에서 바나나가 두 번 등장했지만, 그것은 중요한 게 아닙니다. 심지어 바나나란 단어가 문서2에서 100번 등장했고, 문서3에서 200번 등장했다고 하더라도 바나나의 df는 2가 됩니다.

   **\(3\) idf\(d, t\) : df\(t\)에 반비례하는 수.**

   idf\(d,t\)=log\(n1+df\(t\)\)idf\(d,t\)=log\(n1+df\(t\)\)

   IDF라는 이름을 보고 DF의 역수가 아닐까 생각했다면, IDF는 DF의 역수를 취하고 싶은 것이 맞습니다. 그런데 log와 분모에 1을 더해주는 식에 의아하실 수 있습니다. log를 사용하지 않았을 때, IDF를 DF의 역수\(ndf\(t\)ndf\(t\)라는 식\)로 사용한다면 총 문서의 수 n이 커질 수록, IDF의 값은 기하급수적으로 커지게 됩니다. 그렇기 때문에 log를 사용합니다.

{% embed url="https://wikidocs.net/31698" %}

{% embed url="https://nesoy.github.io/articles/2017-11/tf-idf" %}

**2. BM25**: Okapi BM25는 검색엔진, 추천 시스템 등에서 사용되는 스코어링 알고리즘이다. tf\(term frequency\) 와 idf\(inversed document frequency\) 의 개념을 바탕으로, 문서의 길이까지 고려를 하여 스코어링을 한다.

Okapi BM25의 기본적인 식은 다음과 같다.

![](https://t1.daumcdn.net/cfile/tistory/236C5A47566A8A3629)

식이 꽤 복잡해 보이지만 알고 보면 tf, idf, 문서 길이만 factor로 사용하며

나머지는 이 세 가지 요소들을 어떻게 weight를 주어 스코어링을 할 것인지를 결정하는 부분이다.  


식을 처음부터 살펴보자.

![](https://t1.daumcdn.net/cfile/tistory/261AAA47566A8B2807)

Document \(D\) 에 Query \(Q\) 를 날려 얼마나 일치하는지 score를 얻는 것이 목적이다.

만약 검색에서 이 알고리즘을 사용한다면, score가 높은 순서대로 Document가 정렬되어 검색 결과로 나타날 것이다.

![](https://t1.daumcdn.net/cfile/tistory/2546063A566A8CBF02)

Query를 쪼개면 여러 개의 term이 생길 것이다.

제일 쉽게는 띄어쓰기를 기준으로 쪼갤 수 있을 것이다.

각 term을 Document에 적용한 결과를 모두 더하여 score가 결정된다.

![](https://t1.daumcdn.net/cfile/tistory/2449DE38566A8D3735)

idf의 식이다.

해당 term을 가지고 있는 문서의 갯수 / 전체 문서의 갯수 \(=df\) 를 역수 취하고 로그를 씌운 값이다.

보통 N이 매우 크기 때문에 로그를 씌워 값의 range를 좁혀준다.

\(Document set이 1000000개의 Document들로 이루어져 있고, 그 중 검색하는 term이 나온 문서가 10개라면

로그를 씌우지 않았을 때는 값이 100000 이지만, 로그를 씌우면 5가 된다.\)

![](https://t1.daumcdn.net/cfile/tistory/21361F4D566AF69001)

제일 복잡해 보이는 식이다.

일단 tf\(td\) 는 말 그대로 Document d에서 t라는 term이 얼마나 나타났는지 그 count를 나타내는 것이고,

L\(d\) 는 현재 Target Document d의 길이,

L\(avg\) 는 전체 Document set에 있는 모든 Document 길이의 평균을 나타낸다.

\(여기서 Document의 길이라 함은 term이 몇개인가? 라고 이해하면 되겠다.\)

나머지 k1과 b는, tf와 L값을 어떻게 weight를 주어 계산을 해 줄건지 결정하는 parameter라고 보면 된다.

k1이 0이라면? 모든 텀은 다 지워지고 저 식이 통째로 1이 되겠다.

결국 tf고 L이고 뭐고 아무것도 고려를 안 하겠다는 말이 된다.

k1이 높아지면 높아질수록 tf에 많은 가중치를 두어 계산한다는 뜻이 된다.

그럼 b가 0이라면? 문서의 길이를 고려하지 않겠다는 말이 되고

b가 1에 가까워질수록 문서의 길이에 많은 가중치를 두어 계산한다는 뜻이 되겠다.

\(k1과는 달리 b는 1을 넘을 수 없다.\)

실험적으로, k1은 1.2와 2.0 사이, b는 0.75로 설정하는 것이 제일 올바른 스코어링을 하게 한다고 하지만

어떤 도메인에서 어떤 검색을 실행할 것인가에 따라 두 값을 조정하여 알고리즘을 튜닝할 수 있겠다.

어쨌든 보자면, score가 높아지려면 tf\(td\) 의 값은 높아져야 하고,

L\(d\) / L\(avg\) 의 값은 낮아져야 한다는 것을 알 수 있다.

여기서 tf는 그렇다 쳐도 문서의 길이는 왜 따지냐고 할 수 있는데, 이것도 간단하다.

100단어로 이루어진 문서 중 내가 날린 term이 한번 나오는 것과,

1000단어로 이루어진 문서 중 내가 날린 term이 한번 나오는 것은 매우 다르기 때문이다.

짧은 문서에서 내가 찾는 핵심 term만 딱! 나오는 게,

긴 문서에서 주저리주저리 하다가 어쩌다 내가 찾는 term이 한번 나오는 것보다는 훨씬 매칭이 잘 되는 문서일 것이다.

이제 총정리를 하면, 어떤 문서와 쿼리가 매칭이 잘 되어 높은 score를 얻기 위해서는 :

1. 내가 날린 query 안의 term이 적은 문서에만 있는, 즉 매우 희소하고 자주 쓰이지 않는 단어여야 하며,

2. 문서에서 해당 term이 많이 나와야 하며,

3. 해당 문서의 길이는 짧아야 한다.

로 요약할 수 있겠다!

근데 저 공식은 매우 기본적인 형태이고, 실질적으로 검색 서비스에 사용되는 랭킹 알고리즘은 훠어어어어어얼씬 더 많은 피쳐들을 알고리즘에 적용한다.  
  
[https://jitwo.tistory.com/8](https://jitwo.tistory.com/8)

  


